{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MRC0e0KhQ0S"
   },
   "source": [
    "# Breast cancer detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWd1UlMnhT2s"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1VMqkGvhc3-"
   },
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"breast-cancer-wisconsin.csv\")\n",
    "x = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1000025 5 '?' ... 3 1 1]\n",
      " [1002945 5 '4' ... 3 2 1]\n",
      " [1015425 3 '1' ... 3 1 1]\n",
      " ...\n",
      " [888820 5 '10' ... 8 10 2]\n",
      " [897471 4 '8' ... 10 6 1]\n",
      " [897471 4 '8' ... 10 4 1]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have string values, that should be numeric. This values are string because of the '?' character.** To deal with this we will turn all the \"?\" characters into NaN with to_numeric(). We use for loop because to_numeric function takes an 1D array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x[1])):\n",
    "    x[:, i] = pd.to_numeric(x[:,i], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking care of missing data\n",
    "\n",
    "We have missing data, which represented by \"?\". We have to replace them with meaningful data to process. To do this we will use most_frequent strategy of the SimpleImputer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "imputer.fit(x[:, 1:])\n",
    "x[:, 1:] = imputer.transform(x[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1000025 5.0 3.1375358166189113 ... 3.0 1.0 1.0]\n",
      " [1002945 5.0 4.0 ... 3.0 2.0 1.0]\n",
      " [1015425 3.0 1.0 ... 3.0 1.0 1.0]\n",
      " ...\n",
      " [888820 5.0 10.0 ... 8.0 10.0 2.0]\n",
      " [897471 4.0 8.0 ... 10.0 6.0 1.0]\n",
      " [897471 4.0 8.0 ... 10.0 4.0 1.0]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvxIPVyMhmKp"
   },
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kW3c7UYih0hT"
   },
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bb6jCOCQiAmP"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKYVQH-l5NpE"
   },
   "source": [
    "## Predicting the Test set results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4Hwj34ziWQW"
   },
   "source": [
    "## Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZ-j28aPihZx"
   },
   "source": [
    "## Visualising the Test set results"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMgnogy4MthjceNfhB196rJ",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
